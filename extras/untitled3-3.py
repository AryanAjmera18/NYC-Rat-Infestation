# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xz0FWbSWwUbeX-NdolLaehwW3A4ti3Dr
"""

#%cd /content/drive/MyDrive/Colab Notebooks
#!pip install pyspark

#from pyspark.sql import SparkSession
#from pyspark.sql.functions import count, when, isnull

#spark = SparkSession.builder.appName("RodentInfestation").getOrCreate()

# df = spark.read.csv('/content/drive/MyDrive/Colab Notebooks/Rodent_Inspection_20250504.csv', header=True, inferSchema=False)

# #df.printSchema()
# #df.show(5)
# #df.describe().show()
# #df.select([count(when(isnull(c), c)).alias(c) for c in df.columns]).show()

# from pyspark.sql.functions import to_timestamp

# #df = df.filter(df["Inspection_Date"].isNotNull())

# df = df.filter(
#     (df["Inspection_Date"].isNotNull()) &
#     (df["BOROUGH"].isNotNull()) &
#     (df["LATITUDE"].isNotNull()) &
#     (df["LONGITUDE"].isNotNull()) &
#     (df["LATITUDE"] != 0) &
#     (df["LONGITUDE"] != 0) &
#     (df["RESULT"].isNotNull())
# )

# df = df.withColumn("Inspection_Date", to_timestamp("Inspection_Date", 'MM/dd/yyyy hh:mm:ss a'))

# #df.printSchema()

# #df.select("Inspection_Date").show(10)

# #df.groupBy("Borough").count().show()

# from pyspark.sql.functions import year, month
# from datetime import datetime
# current_year = datetime.now().year

# # from pyspark.sql.functions import to_date

# # df = df.withColumn("Inspection_Date", to_date("Inspection_Date", 'MM/dd/yyyy'))

# df = df.withColumn("Year", year("Inspection_Date"))

# df = df.filter(
#     (df["Year"] >= 2009) & (df["Year"] <= current_year)
# )
# #df.printSchema()

# df.groupBy("Year").count().orderBy("Year").show()

# #df.select("RESULT").distinct().show(truncate=False)

# #df.groupBy("Borough", "Result").count().orderBy("Borough").show()

# #df.groupBy("Zip_Code").count().orderBy('count', ascending=False).show(10)

# #!pip install folium

# #!pip install streamlit-folium
import pandas as pd
import folium
from folium.plugins import HeatMap
import streamlit as st
from streamlit_folium import st_folium


@st.cache_data
def load_data():
    return pd.read_csv("/content/drive/MyDrive/Colab Notebooks/rodent_cleaned_data.csv/part-00000-d122803e-afca-406b-a0b3-194a01fa47e2-c000.csv")

geo_df = load_data()

@st.cache_data
def filter_and_prepare_data(geo_df, selected_year):
    df_year = geo_df[geo_df['Year'] == selected_year]
    df_year = df_year.dropna(subset=['LATITUDE', 'LONGITUDE'])
    df_year['lat_rounded'] = df_year['LATITUDE'].round(3)
    df_year['lon_rounded'] = df_year['LONGITUDE'].round(3)
    heat_data = df_year.groupby(['lat_rounded', 'lon_rounded']).size().reset_index(name='count')
    heat_list = heat_data[['lat_rounded', 'lon_rounded', 'count']].values.tolist()
    return df_year, heat_list

@st.cache_resource
def create_heatmap_map(heat_list):
    m = folium.Map(location=[40.867726534028, -73.887461100839], zoom_start=11)
    HeatMap(heat_list).add_to(m)
    return m

# Process
geo_df = load_data()

# Ensure numeric
geo_df['Year'] = pd.to_numeric(geo_df['Year'], errors='coerce')
geo_df['LATITUDE'] = pd.to_numeric(geo_df['LATITUDE'], errors='coerce')
geo_df['LONGITUDE'] = pd.to_numeric(geo_df['LONGITUDE'], errors='coerce')

years = sorted(geo_df['Year'].dropna().unique())
selected_year = st.selectbox("Select Year:", years)

df_year, heat_list = filter_and_prepare_data(geo_df, selected_year)

st.write(f"Total inspections for {selected_year}: {len(df_year)}")

# Build the map
m = create_heatmap_map(heat_list)

# Display map
st_folium(m, width=700, height=500)
#m

#print(geo_df.shape)
#print(geo_df.head())

#m.save("heatmap.html")

#!pip install streamlit pyngrok
#from pyngrok import ngrok
#!ngrok config add-authtoken 2weUsgpHo13JMTYpHKuChzlPMcD_5QeiDZdEhqFcFrJnvn9AM
#public_url = ngrok.connect("http://localhost:8501")
#print(public_url)
#!streamlit run untitled3.py